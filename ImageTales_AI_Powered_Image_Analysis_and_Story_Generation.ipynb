{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHoPTF6IeiB4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from openai import AzureOpenAI\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "import httpx\n",
        "\n",
        "# Azure Vision API settings\n",
        "VISION_ENDPOINT = \"https://obgr56.cognitiveservices.azure.com/\"\n",
        "VISION_KEY = \"4t8bhp9U06l0n9xUgTsfxRnREmxUPVYs1Sf8mzZSlYcSaDMhZd0DJQQJ99ALACYeBjFXJ3w3AAAFACOGus8x\"\n",
        "\n",
        "# Azure OpenAI API settings\n",
        "OPENAI_API_KEY = \"5O55vdSCkfwS7PxNgow6tJKQsqoW5KM6UjVd9FE68r0oAbPST46vJQQJ99ALACfhMk5XJ3w3AAAAACOGTjAt\"\n",
        "OPENAI_ENDPOINT = \"https://abill-m4abvruz-swedencentral.openai.azure.com/\"\n",
        "DEPLOYMENT_NAME = \"gpt-4\"\n",
        "\n",
        "# Azure Speech service settings\n",
        "SPEECH_KEY = \"1oAXVuYvHfhthYHFyNC0plSsRhWzqSLk4AuP1jFe9q2DqAHmOIRHJQQJ99ALACYeBjFXJ3w3AAAYACOG21H7\"\n",
        "SPEECH_REGION = \"eastus\"\n",
        "\n",
        "def initialize_vision_client():\n",
        "    \"\"\"Initialize Azure Vision client\"\"\"\n",
        "    try:\n",
        "        return ComputerVisionClient(\n",
        "            endpoint=VISION_ENDPOINT,\n",
        "            credentials=CognitiveServicesCredentials(VISION_KEY)\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Vision client: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def initialize_openai_client():\n",
        "    \"\"\"Initialize Azure OpenAI client\"\"\"\n",
        "    try:\n",
        "        http_client = httpx.Client()\n",
        "        client = AzureOpenAI(\n",
        "            api_key=OPENAI_API_KEY,\n",
        "            api_version=\"2024-02-15-preview\",\n",
        "            azure_endpoint=OPENAI_ENDPOINT,\n",
        "            http_client=http_client\n",
        "        )\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing OpenAI client: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def analyze_image(vision_client, image_path):\n",
        "    \"\"\"Analyze image using Azure Vision API\"\"\"\n",
        "    try:\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            description = vision_client.describe_image_in_stream(image_file)\n",
        "            image_file.seek(0)\n",
        "            text_result = vision_client.recognize_printed_text_in_stream(image_file)\n",
        "\n",
        "            image_description = []\n",
        "\n",
        "            if description.captions:\n",
        "                image_description.append(f\"Main caption: {description.captions[0].text}\")\n",
        "\n",
        "            if text_result:\n",
        "                text_content = []\n",
        "                for region in text_result.regions:\n",
        "                    for line in region.lines:\n",
        "                        line_text = ' '.join([word.text for word in line.words])\n",
        "                        text_content.append(line_text)\n",
        "                if text_content:\n",
        "                    image_description.append(\"Text found in image: \" + \" \".join(text_content))\n",
        "\n",
        "            return \"\\n\".join(image_description)\n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing image: {str(e)}\"\n",
        "\n",
        "def generate_story(openai_client, image_analysis):\n",
        "    \"\"\"Generate a story based on image analysis\"\"\"\n",
        "    if not openai_client:\n",
        "        return \"Error: OpenAI client not properly initialized\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Based on the following image analysis, create an engaging short story:\n",
        "    {image_analysis}\n",
        "\n",
        "    Please create a creative and descriptive story that captures the essence of this image.\n",
        "    The story should be 3-4 paragraphs long and include vivid details from the image description.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=DEPLOYMENT_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a creative storyteller who crafts engaging narratives based on visual descriptions.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=500\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error generating story: {str(e)}\"\n",
        "\n",
        "def text_to_speech_file(text, output_file=None):\n",
        "    \"\"\"Convert text to speech using Azure Speech Service and save to file\"\"\"\n",
        "    try:\n",
        "        speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)\n",
        "        speech_config.speech_synthesis_voice_name = \"en-US-JennyNeural\"\n",
        "\n",
        "        if output_file is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            output_file = f\"speech_output_{timestamp}.wav\"\n",
        "\n",
        "        audio_config = speechsdk.audio.AudioOutputConfig(filename=output_file)\n",
        "        speech_synthesizer = speechsdk.SpeechSynthesizer(\n",
        "            speech_config=speech_config,\n",
        "            audio_config=audio_config\n",
        "        )\n",
        "\n",
        "        result = speech_synthesizer.speak_text_async(text).get()\n",
        "\n",
        "        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
        "            print(f\"Speech synthesis completed successfully. Audio saved to: {output_file}\")\n",
        "            return output_file\n",
        "        else:\n",
        "            print(f\"Error synthesizing audio: {result.reason}\")\n",
        "            if result.reason == speechsdk.ResultReason.Canceled:\n",
        "                cancellation_details = result.cancellation_details\n",
        "                print(f\"Speech synthesis canceled: {cancellation_details.reason}\")\n",
        "                if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
        "                    print(f\"Error details: {cancellation_details.error_details}\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in text-to-speech conversion: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"Initializing clients...\")\n",
        "    try:\n",
        "        # Create output directory\n",
        "        output_dir = \"speech_output\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Initialize clients\n",
        "        vision_client = initialize_vision_client()\n",
        "        openai_client = initialize_openai_client()\n",
        "\n",
        "        if not vision_client or not openai_client:\n",
        "            print(\"Failed to initialize one or more clients. Exiting...\")\n",
        "            return\n",
        "\n",
        "        while True:\n",
        "            # Get image path from user\n",
        "            image_path = input(\"\\nEnter the path to your image (or 'quit' to exit): \")\n",
        "\n",
        "            if image_path.lower() == 'quit':\n",
        "                break\n",
        "\n",
        "            if not os.path.exists(image_path):\n",
        "                print(f\"Error: File '{image_path}' does not exist.\")\n",
        "                continue\n",
        "\n",
        "            # Process image and generate story\n",
        "            print(\"\\nAnalyzing image...\")\n",
        "            image_analysis = analyze_image(vision_client, image_path)\n",
        "\n",
        "            print(\"\\nImage Analysis Results:\")\n",
        "            print(image_analysis)\n",
        "\n",
        "            print(\"\\nGenerating story...\")\n",
        "            story = generate_story(openai_client, image_analysis)\n",
        "\n",
        "            print(\"\\nGenerated Story:\")\n",
        "            print(story)\n",
        "\n",
        "            # Convert story to speech\n",
        "            print(\"\\nConverting story to speech...\")\n",
        "            output_file = os.path.join(output_dir, f\"story_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav\")\n",
        "            result_file = text_to_speech_file(story, output_file)\n",
        "\n",
        "            if result_file:\n",
        "                print(f\"\\nAudio file size: {os.path.getsize(result_file) / 1024:.2f} KB\")\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}